{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2de237bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /opt/anaconda3/lib/python3.12/site-packages (5.1.2)\n",
      "Requirement already satisfied: faiss-cpu in /opt/anaconda3/lib/python3.12/site-packages (1.11.0)\n",
      "Requirement already satisfied: openai in /opt/anaconda3/lib/python3.12/site-packages (2.6.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (4.47.1)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (4.66.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (2.7.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (0.27.1)\n",
      "Requirement already satisfied: Pillow in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (4.15.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in /opt/anaconda3/lib/python3.12/site-packages (from faiss-cpu) (1.26.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from faiss-cpu) (24.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (0.11.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (2.11.9)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.12/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (75.1.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/anaconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/anaconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers faiss-cpu openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11086c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading FAISS index...\n",
      "Loading metadata...\n",
      "Loaded model: BAAI/bge-small-en-v1.5\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import faiss\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "# LOAD FAISS + METADATA + MODEL\n",
    "\n",
    "print(\"Loading FAISS index...\")\n",
    "index = faiss.read_index(\"shl_faiss.index\")\n",
    "\n",
    "print(\"Loading metadata...\")\n",
    "with open(\"shl_metadata.pkl\", \"rb\") as f:\n",
    "    meta = pickle.load(f)\n",
    "\n",
    "df = meta[\"df\"]\n",
    "model_name = meta[\"model_name\"]\n",
    "model = SentenceTransformer(model_name)\n",
    "\n",
    "print(\"Loaded model:\", model_name)\n",
    "\n",
    "# Get top-k results from FAISS\n",
    "def semantic_search(query, top_k=20):\n",
    "    query_emb = model.encode([query], normalize_embeddings=True)\n",
    "    distances, indices = index.search(query_emb, top_k)\n",
    "\n",
    "    results = []\n",
    "    for idx in indices[0]:\n",
    "        row = df.iloc[idx].to_dict()\n",
    "        results.append(row)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "#  LLM Re-ranking \n",
    "\n",
    "def rerank_with_llm(query, retrieved_items, top_k=10):\n",
    "    \"\"\"\n",
    "    You can use OpenAI, Gemini, or any LLM.\n",
    "    I'll provide a clean OpenAI example below.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        from openai import OpenAI\n",
    "        client = OpenAI()\n",
    "\n",
    "        context = \"\\n\\n\".join(\n",
    "            [f\"[{i}] {item['name']} — {item['description']}\" for i, item in enumerate(retrieved_items)]\n",
    "        )\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "        You are a ranking model for SHL assessment recommendations.\n",
    "\n",
    "        Query:\n",
    "        {query}\n",
    "\n",
    "        Below is a list of candidate assessments. Rank them from most relevant to least relevant.\n",
    "\n",
    "        {context}\n",
    "\n",
    "        Return ONLY a list of ranked indexes (like: 3,0,1,2,...)\n",
    "        \"\"\"\n",
    "\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "\n",
    "        ranked_order = response.choices[0].message.content.strip()\n",
    "        ranked_order = [int(x) for x in ranked_order.split(\",\")]\n",
    "\n",
    "        reranked = [retrieved_items[i] for i in ranked_order[:top_k]]\n",
    "        return reranked\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"LLM re-ranking failed, using raw results:\", e)\n",
    "        return retrieved_items[:top_k]\n",
    "\n",
    "\n",
    "\n",
    "# Format results \n",
    "\n",
    "def format_output(items):\n",
    "    formatted = []\n",
    "\n",
    "    for item in items:\n",
    "        # Clean duration safely \n",
    "        duration_value = item.get(\"Duration\", None)\n",
    "\n",
    "        try:\n",
    "            if duration_value is None or str(duration_value).lower() == \"nan\" or duration_value == \"\":\n",
    "                duration_clean = None\n",
    "            else:\n",
    "                duration_clean = int(float(duration_value))\n",
    "        except:\n",
    "            duration_clean = None\n",
    "\n",
    "        formatted.append({\n",
    "            \"url\": item.get(\"Link\", \"\"),\n",
    "            \"name\": item.get(\"Assessment Name\", \"\"),\n",
    "            \"description\": item.get(\"Description\", \"\"),\n",
    "            \"duration\": duration_clean,\n",
    "            \"adaptive_support\": item.get(\"Adaptive/IRT (Yes/No)\", \"Unknown\"),\n",
    "            \"remote_support\": item.get(\"Remote Support (Yes/No)\", \"Unknown\"),\n",
    "            \"test_type\": [item.get(\"Test Type\", \"Unknown\")]\n",
    "        })\n",
    "\n",
    "    return {\"recommended_assessments\": formatted}\n",
    "\n",
    "\n",
    "# MAIN PIPELINE FUNCTION TO CALL FROM API\n",
    "\n",
    "def recommend(query, use_llm=True):\n",
    "    retrieved = semantic_search(query, top_k=20)\n",
    "\n",
    "    if use_llm:\n",
    "        final_items = rerank_with_llm(query, retrieved, top_k=10)\n",
    "    else:\n",
    "        final_items = retrieved[:10]\n",
    "\n",
    "    output = format_output(final_items)\n",
    "    return output\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2338b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM re-ranking failed, using raw results: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\n",
      "{'recommended_assessments': [{'url': 'https://www.shl.com/products/product-catalog/view/python-new/', 'name': 'Python (New)', 'description': 'Multi-choice test that measures the knowledge of Python programming, databases, modules and library.', 'duration': 11, 'adaptive_support': 'No', 'remote_support': 'Yes', 'test_type': ['K']}, {'url': 'https://www.shl.com/products/product-catalog/view/job-control-language-new/', 'name': 'Job Control Language (New)', 'description': 'Multi-choice test that measures the knowledge of JCL libraries, parameters, statements, datasets, generation of data groups and conditional processing.', 'duration': 10, 'adaptive_support': 'No', 'remote_support': 'Yes', 'test_type': ['K']}, {'url': 'https://www.shl.com/products/product-catalog/view/verify-interactive-g-candidate-report/', 'name': 'Verify Interactive G+ Candidate Report', 'description': 'Verify Interactive G+ Candidate Report', 'duration': None, 'adaptive_support': 'No', 'remote_support': 'Yes', 'test_type': ['A']}, {'url': 'https://www.shl.com/products/product-catalog/view/r-programming-new/', 'name': 'R Programming (New)', 'description': 'Multi-choice test that measures the knowledge of R programming and its application in statistics.', 'duration': 13, 'adaptive_support': 'No', 'remote_support': 'Yes', 'test_type': ['K']}, {'url': 'https://www.shl.com/products/product-catalog/view/smart-interview-live-coding/', 'name': 'Smart Interview Live Coding', 'description': 'Smart Interview Live Coding is a real-time online coding interview, with a compiler interface. It enables one-to-one, panel and group interviews. Use Smart Interview Live Coding to comprehensively evaluate candidates’ skills across various technical roles and hire the best coding talent. The language availability for the candidate and interviewer interface is English (US), Simplified Chinese, Castilian Spanish, Japanese. Please note that the questions themselves are available as standard in US English only. The language availability for the admin interface is US English only.', 'duration': None, 'adaptive_support': 'No', 'remote_support': 'Yes', 'test_type': ['K']}, {'url': 'https://www.shl.com/products/product-catalog/view/agile-software-development/', 'name': 'Agile Software Development', 'description': 'Multi-choice test that measures the knowledge of agile methodology, scrum, feature driven software development, incremental and iterative development and processes involved in agile software development.', 'duration': 7, 'adaptive_support': 'No', 'remote_support': 'Yes', 'test_type': ['K']}, {'url': 'https://www.shl.com/products/product-catalog/view/mulesoft-development-new/', 'name': 'MuleSoft Development (New)', 'description': 'Multi-choice test that measures the knowledge of MuleSoft basic concepts, APIs and web services, Mule flow and scope, connectors and deployment.', 'duration': 17, 'adaptive_support': 'No', 'remote_support': 'Yes', 'test_type': ['K']}, {'url': 'https://www.shl.com/products/product-catalog/view/following-instructions-v1-uk-r1/', 'name': 'Following Instructions v1 - UK (R1)', 'description': \"This test measures a candidate's ability to follow detailed instructions and then select the correct course of action. Candidates are presented with a set of rules and need to choose the appropriate response for various situations based on the rules given.\", 'duration': 8, 'adaptive_support': 'No', 'remote_support': 'Yes', 'test_type': ['K']}, {'url': 'https://www.shl.com/products/product-catalog/view/cobol-programming-new/', 'name': 'COBOL Programming (New)', 'description': 'Multi-choice test that measures the knowledge of COBOL programming fundamentals, programming structure and different types of application processing.', 'duration': 10, 'adaptive_support': 'No', 'remote_support': 'Yes', 'test_type': ['K']}, {'url': 'https://www.shl.com/products/product-catalog/view/verify-interactive-ability-report/', 'name': 'Verify Interactive Ability Report', 'description': 'Verify Interactive Ability Report', 'duration': None, 'adaptive_support': 'No', 'remote_support': 'Yes', 'test_type': ['A']}]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# TEST THE SYSTEM\n",
    "q = \"I am hiring a Python developer who works well with teams\"\n",
    "result = recommend(q, use_llm=True)  # turn off LLM for testing\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c31a5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
